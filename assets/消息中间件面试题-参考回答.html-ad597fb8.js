import{_ as p}from"./plugin-vue_export-helper-c27b6911.js";import{o,c as t,f as r}from"./app-466c0ef2.js";const i={},l=r('<h1 id="消息中间件面试题-参考回答" tabindex="-1"><a class="header-anchor" href="#消息中间件面试题-参考回答" aria-hidden="true">#</a> 消息中间件面试题-参考回答</h1><p>讲解知识点架构：</p><img src="https://tommy-blog-bucket.oss-cn-beijing.aliyuncs.com/blog/20231215180607.png" alt="知识点架构" style="zoom:50%;"><hr><p>RabbitMQ的使用场景：</p><ul><li>异步发送（验证码、短信、邮件）</li><li>MySQL和Redis、ES之间的数据同步</li><li>分布式事务</li><li>削峰填谷</li></ul><hr><p><strong>面试官</strong>：RabbitMQ-如何保证消息不丢失</p><blockquote><p>RabbitMQ可能导师消息丢失的场景：</p><figure><img src="https://tommy-blog-bucket.oss-cn-beijing.aliyuncs.com/blog/20231215181121.png" alt="可能导致消息丢失的情况" tabindex="0" loading="lazy"><figcaption>可能导致消息丢失的情况</figcaption></figure><ol><li><p>RabbitMQ提供了**publisher confirm（生产者确认机制）**机制来避免消息发送到MQ过程中丢失。消息发送到MQ之后，会返回一个结果给发送着，表示消息是否处理成功。</p><figure><img src="https://tommy-blog-bucket.oss-cn-beijing.aliyuncs.com/blog/20231215182558.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>消息发送失败后如何处理？</p><ul><li>回调方法及时重发</li><li>记录日志</li><li>保存到数据库然后定时重发（做一个定时任务），成功发送后即可删除表中记录的数据。</li></ul></li><li><p>消息持久化，保证当MQ宕机时，内存队列中的数据不会丢失。MQ默认是内存存储数据，开启持久化功能可以确保缓存在MQ中的消息不丢失。</p><p>![](/Users/tommy/Library/Application Support/typora-user-images/image-20231215183127963.png)</p></li><li><p>消费者确认机制，防止消费者宕机导致消息丢失。RabbitMQ支持消费者确认机制，即消费者处理消息后，可以向MQ发送ack回执，MQ收到ack回执后才会删除该消息，而Spring AMQP则允许三种确认模式：</p><ul><li>manual：手动ack，需要在业务代码结束后，调用api发送ack</li><li>auto：自动ack，由spring检测listener代码是否出现了异常，没有异常则返回ack，抛出异常则返回nack</li><li>none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除</li></ul><p>![](/Users/tommy/Library/Application Support/typora-user-images/image-20231215183715685.png)</p></li></ol></blockquote><p><strong>候选人</strong>：</p><p>嗯！我们当时MYSQL和Redis的数据双写一致性就是采用RabbitMQ实现同步的，这里面就要求了消息的高可用性，我们要保证消息的不丢失。主要从三个层面考虑</p><p>第一个是开启生产者确认机制，确保生产者的消息能到达队列，如果报错可以先记录到日志中，再去修复数据</p><p>第二个是开启持久化功能，确保消息未消费前在队列中不会丢失，其中的交换机、队列、和消息都要做持久化</p><p>第三个是开启消费者确认机制为auto，由spring确认消息处理成功后完成ack，当然也需要设置一定的重试次数，我们当时设置了3次，如果重试3次还没有收到消息，就将失败后的消息投递到异常交换机，交由人工处理</p><hr><p><strong>面试官</strong>：RabbitMQ消息的重复消费问题如何解决的</p><blockquote><p>重复消费问题可能的导致原因？</p><ul><li>网络抖动</li><li>消费者挂了</li></ul><p>上述的两个原因发生在消费者刚刚消费完消息，但是还没有来得及向MQ发送ack，导致MQ迟迟接受不到ack，误认为消费失败，则启动重试机制，则会导致下一次又重新消费一次数据。</p></blockquote><p><strong>候选人</strong>：</p><p>嗯，这个我们还真遇到过，是这样的，我们当时消费者是设置了自动确认机制，当服务还没来得及给MQ确认的时候，服务宕机了，导致服务重启之后，又消费了一次消息。这样就重复消费了</p><p>因为我们当时处理的支付（订单|业务唯一标识），它有一个业务的唯一标识，我们再处理消息时，先到数据库查询一下，这个数据是否存在，如果不存在，说明没有处理过，这个时候就可以正常处理这个消息了。如果已经存在这个数据了，就说明消息重复消费了，我们就不需要再消费了。</p><hr><p><strong>面试官</strong>：那你还知道其他的解决方案吗？</p><p><strong>候选人</strong>：</p><p>其实这个就是典型的幂等的问题，比如，redis分布式锁、数据库的锁都是可以的，但是毕竟使用锁，效率肯定不如上面的方法。</p><hr><p><strong>面试官</strong>：RabbitMQ中死信交换机 ? （RabbitMQ延迟队列有了解过嘛）</p><blockquote><p>延迟队列？进入队列的消息会被延迟消费的队列</p><p>场景：超时订单、限时优惠、定时发布</p></blockquote><p><strong>候选人</strong>：</p><p>我们当时的xx项目有一个xx业务，需要用到延迟队列，其中就是使用RabbitMQ来实现的。</p><p>延迟队列就是用到了死信交换机和TTL（消息存活时间）实现的。</p><p>如果消息超时未消费就会变成死信，在RabbitMQ中如果消息成为死信，队列可以绑定一个死信交换机，在死信交换机上可以绑定其他队列，在我们发消息的时候可以按照需求指定TTL的时间，这样就实现了延迟队列的功能了，消费端之需要监听绑定在死信交换机上的队列即可实现延迟消费消息。</p><p>我记得RabbitMQ还有一种方式可以实现延迟队列，在RabbitMQ中安装一个死信插件，这样更方便一些，我们只需要在声明交互机的时候，指定这个就是死信交换机，然后在发送消息的时候直接指定超时时间就行了，相对于死信交换机+TTL要省略了一些步骤</p><hr><p><strong>面试官</strong>：如果有100万消息堆积在MQ , 如何解决 ?</p><blockquote><p>产生消息堆积的原因？当生产者生产消息的速度大于消费者消费消息的速度时，可能会发生大量的消息堆积在MQ中。</p><p>提供三个具体的思路去解决这个问题？</p><ol><li>增加更多的消费者，提高消费的速度</li><li>在消费者内开启线程池加快消息的处理速度</li><li>扩大队列容积，提高堆积上线（<strong>惰性队列</strong>）</li></ol><p><strong>惰性队列？</strong></p><ul><li>接收到消息后直接存储到磁盘中，而不是内存中</li><li>消费者要消费消息时才会从磁盘中读取并加载到内存中</li><li>支持数百万条的消息存储</li></ul></blockquote><p><strong>候选人</strong>：</p><p>我在实际的开发中，没遇到过这种情况，不过我在一定程度上测试过这个问题。</p><p>第一：提高消费者的消费能力，可以使用多线程消费任务</p><p>第二：增加更多消费者，提高消费速度，使用工作队列模式, 设置多个消费者消费消费同一个队列中的消息</p><p>第三：扩大队列容积，提高堆积上限</p><p>可以使用RabbitMQ惰性队列，惰性队列的好处主要是</p><ol><li><p>接收到消息后直接存入磁盘而非内存</p></li><li><p>消费者要消费消息时才会从磁盘中读取并加载到内存</p></li><li><p>支持数百万条的消息存储</p></li></ol><hr><p><strong>面试官</strong>：RabbitMQ的高可用机制有了解过嘛</p><blockquote><ul><li>在生产环境下，使用集群保证高可用性</li><li>普通集群、镜像集群、仲裁队列</li></ul></blockquote><p><strong>候选人</strong>：</p><p>嗯，熟悉的~</p><p>我们当时项目在生产环境下，使用的集群，当时搭建是镜像模式集群，使用了3台机器。</p><p>镜像队列结构是一主多从，所有操作都是主节点完成，然后同步给镜像节点，如果主节点宕机后，镜像节点会替代成新的主节点，不过在主从同步完成前，主节点就已经宕机，可能出现数据丢失</p><p><strong>面试官</strong>：那出现丢数据怎么解决呢？</p><p><strong>候选人</strong>：</p><p>我们可以采用仲裁队列，与镜像队列一样，都是主从模式，支持主从数据同步，主从同步基于Raft协议，强一致。</p><p>并且使用起来也非常简单，不需要额外的配置，在声明队列的时候只要指定这个是仲裁队列即可</p><p><strong>面试官</strong>：Kafka是如何保证消息不丢失</p><p><strong>候选人</strong>：</p><p>嗯，这个保证机制很多，在发送消息到消费者接收消息，在每个阶段都有可能会丢失消息，所以我们解决的话也是从多个方面考虑</p><p>第一个是生产者发送消息的时候，可以使用异步回调发送，如果消息发送失败，我们可以通过回调获取失败后的消息信息，可以考虑重试或记录日志，后边再做补偿都是可以的。同时在生产者这边还可以设置消息重试，有的时候是由于网络抖动的原因导致发送不成功，就可以使用重试机制来解决</p><p>第二个在broker中消息有可能会丢失，我们可以通过kafka的复制机制来确保消息不丢失，在生产者发送消息的时候，可以设置一个acks，就是确认机制。我们可以设置参数为all，这样的话，当生产者发送消息到了分区之后，不仅仅只在leader分区保存确认，在follwer分区也会保存确认，只有当所有的副本都保存确认以后才算是成功发送了消息，所以，这样设置就很大程度了保证了消息不会在broker丢失</p><p>第三个有可能是在消费者端丢失消息，kafka消费消息都是按照offset进行标记消费的，消费者默认是自动按期提交已经消费的偏移量，默认是每隔5s提交一次，如果出现重平衡的情况，可能会重复消费或丢失数据。我们一般都会禁用掉自动提价偏移量，改为手动提交，当消费成功以后再报告给broker消费的位置，这样就可以避免消息丢失和重复消费了</p><p><strong>面试官</strong>：Kafka中消息的重复消费问题如何解决的</p><p><strong>候选人</strong>：</p><p>kafka消费消息都是按照offset进行标记消费的，消费者默认是自动按期提交已经消费的偏移量，默认是每隔5s提交一次，如果出现重平衡的情况，可能会重复消费或丢失数据。我们一般都会禁用掉自动提价偏移量，改为手动提交，当消费成功以后再报告给broker消费的位置，这样就可以避免消息丢失和重复消费了</p><p>为了消息的幂等，我们也可以设置唯一主键来进行区分，或者是加锁，数据库的锁，或者是redis分布式锁，都能解决幂等的问题</p><p><strong>面试官</strong>：Kafka是如何保证消费的顺序性</p><p><strong>候选人</strong>：</p><p>kafka默认存储和消费消息，是不能保证顺序性的，因为一个topic数据可能存储在不同的分区中，每个分区都有一个按照顺序的存储的偏移量，如果消费者关联了多个分区不能保证顺序性</p><p>如果有这样的需求的话，我们是可以解决的，把消息都存储同一个分区下就行了，有两种方式都可以进行设置，第一个是发送消息时指定分区号，第二个是发送消息时按照相同的业务设置相同的key，因为默认情况下分区也是通过key的hashcode值来选择分区的，hash值如果一样的话，分区肯定也是一样的</p><p><strong>面试官</strong>：Kafka的高可用机制有了解过嘛</p><p><strong>候选人</strong>：</p><p>嗯，主要是有两个层面，第一个是集群，第二个是提供了复制机制</p><p>kafka集群指的是由多个broker实例组成，即使某一台宕机，也不耽误其他broker继续对外提供服务</p><p>复制机制是可以保证kafka的高可用的，一个topic有多个分区，每个分区有多个副本，有一个leader，其余的是follower，副本存储在不同的broker中；所有的分区副本的内容是都是相同的，如果leader发生故障时，会自动将其中一个follower提升为leader，保证了系统的容错性、高可用性</p><p><strong>面试官</strong>：解释一下复制机制中的ISR</p><p><strong>候选人</strong>：</p><p>ISR的意思是in-sync replica，就是需要同步复制保存的follower</p><p>其中分区副本有很多的follower，分为了两类，一个是ISR，与leader副本同步保存数据，另外一个普通的副本，是异步同步数据，当leader挂掉之后，会优先从ISR副本列表中选取一个作为leader，因为ISR是同步保存数据，数据更加的完整一些，所以优先选择ISR副本列表</p><p><strong>面试官</strong>：Kafka数据清理机制了解过嘛</p><p><strong>候选人</strong>：</p><p>嗯，了解过~~</p><p>Kafka中topic的数据存储在分区上，分区如果文件过大会分段存储segment</p><p>每个分段都在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储，这样分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理。</p><p>在kafka中提供了两个日志的清理策略：</p><p>第一，根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时（ 7天）</p><p>第二是根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。这个默认是关闭的</p><p>这两个策略都可以通过kafka的broker中的配置文件进行设置</p><p><strong>面试官</strong>：Kafka中实现高性能的设计有了解过嘛</p><p><strong>候选人</strong>：</p><p>Kafka 高性能，是多方面协同的结果，包括宏观架构、分布式存储、ISR 数据同步、以及高效的利用磁盘、操作系统特性等。主要体现有这么几点：</p><p>消息分区：不受单台服务器的限制，可以不受限的处理更多的数据</p><p>顺序读写：磁盘顺序读写，提升读写效率</p><p>页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问</p><p>零拷贝：减少上下文切换及数据拷贝</p><p>消息压缩：减少磁盘IO和网络IO</p><p>分批发送：将消息打包批量发送，减少网络开销</p>',94),a=[l];function s(n,e){return o(),t("div",null,a)}const b=p(i,[["render",s],["__file","消息中间件面试题-参考回答.html.vue"]]);export{b as default};
